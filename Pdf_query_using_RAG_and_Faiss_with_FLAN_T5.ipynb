{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dgB8cum7x67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2892886c-0e50-4eac-d2d9-44236d11f124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers langchain\n",
        "!pip install -U langchain-community\n",
        "!pip install pypdf\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain_huggingface\n",
        "\n",
        "\n",
        "import pypdf\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import InferenceClient\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model_name = \"microsoft/layoutlm-base-uncased\"\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "embedder = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_file_path):\n",
        "    \"\"\"Extracts text from a PDF file using pypdf.\"\"\"\n",
        "    with open(pdf_file_path, 'rb') as f:\n",
        "        pdf_reader = pypdf.PdfReader(f)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def create_faiss_index(text_data, embedder):\n",
        "    \"\"\"Creates a FAISS index for text data.\"\"\"\n",
        "    chunks = text_data.split(\"\\n\")\n",
        "\n",
        "    vectorstore = FAISS.from_texts(chunks, embedder)\n",
        "    return vectorstore\n",
        "\n",
        "def handle_user_input(user_question, pdf_file_path):\n",
        "    \"\"\"Handles user input, searches for relevant text, and generates a response.\"\"\"\n",
        "\n",
        "    pdf_text = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "    global vectorstore\n",
        "    try:\n",
        "        vectorstore\n",
        "    except NameError:\n",
        "        vectorstore = create_faiss_index(pdf_text, embedder)\n",
        "\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    relevant_text = retriever.get_relevant_documents(user_question)\n",
        "\n",
        "    response = generate_response_from_inference_api(user_question, relevant_text)\n",
        "\n",
        "    return response\n",
        "\n",
        "def generate_response_from_inference_api(user_question, relevant_text):\n",
        "    \"\"\"Sends a request to the Hugging Face Inference API.\"\"\"\n",
        "    sec_key = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = sec_key\n",
        "\n",
        "    url = \"https://api-inference.huggingface.co/models/google/flan-t5-large\"\n",
        "    headers = {\"Authorization\": f\"Bearer {os.environ['HUGGINGFACEHUB_API_TOKEN']}\"}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The PDF document says: {relevant_text}\n",
        "    Question: {user_question}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    data = {\"inputs\": prompt}\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[0][\"generated_text\"]\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}\"\n",
        "\n",
        "pdf_file_path = \"budget_speech.pdf\"\n",
        "user_question = \"what is the Vision for Amrit Kaal?\"\n",
        "response = handle_user_input(user_question, pdf_file_path)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz_Uno5bPxxB",
        "outputId": "0f1905ec-eb8b-4563-f0f6-bdd335763152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LayoutLMForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pursuit of ‘ Viksit Bharat’. In line with the strategy set out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file_path = \"budget_speech.pdf\"\n",
        "user_question =  \"How much the agriculture target will be increased to \"\n",
        "response = handle_user_input(user_question, pdf_file_path)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "l8efQkOpijRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01357f4-0b44-4298-ecc1-7ae5dc61e2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 crore farmers across the country will be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3uLkdDemDgCb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}